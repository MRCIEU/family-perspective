---
title: "Family vs unrelated power / bias tradeoff in the presence of assortative mating"
output: html_notebook
---

## Cross trait assortative mating 

I’ve been thinking about trying to answer the question initially posed by Matt in a slightly different way. Given cross-trait assortative mating (e.g. between height and intelligence) generates correlation between height and causal variants for intelligence, I’m trying to create a visualisation of what fraction of GWAS discovered variants for height will be false positives (i.e. truly causal for intelligence, only associating due to AM). As a function of increasing sample size (and genetic architecture and spousal correlation). I’m thinking about this because GWAS hits are often used for downstream inference and biased effects don’t matter – so to what extent is ‘business-as-usual’ gonna start generating false positives? 


$$
\begin{aligned}
x_i &= \gamma_i g_{x,i}+C_i+u_i \\
y_i &= \beta_i x_i + s_y + C_i + v_i
\end{aligned}
$$

Covariance between a score for x and a score for y will depend on 

$$
cov(g_{x}, g_y) = \frac{1}{4} cov(g_{x,o}, x_o) cov(s_{y,o},y_o) \rho
$$

Simulation setup to check this

```{r}
library(simulateGP)
library(dplyr)
library(ggplot2)
library(MASS)
set.seed(12345)

generate_individuals <- function(n, maf = 0.5, bgx = 0.5, bgy = 0.5, bxy = 0.3, bux=0.1, buy=0.1)
{
	nm <- n
	nf <- n
	gxm <- make_geno(nid=nm, nsnp=1, af=maf)
	gym <- make_geno(nid=nm, nsnp=1, af=maf)
	um <- rnorm(n)
	xm <- make_phen(eff=c(bgx, bux), indep=cbind(gxm, um))
	ym <- make_phen(eff=c(bxy, bgy, buy), indep=cbind(xm, gym, um))
	gxf <- make_geno(nid=nf, nsnp=1, af=maf)
	gyf <- make_geno(nid=nf, nsnp=1, af=maf)
	uf <- rnorm(n)
	xf <- make_phen(eff=c(bgx, bux), indep=cbind(gxf, uf))
	yf <- make_phen(eff=c(bxy, bgy, buy), indep=cbind(xf, gyf, uf))
	return(tibble(gxm, gxf, gym, gyf, xm, xf, ym, yf, um, uf))
}
```

Match males and females to make assorted spouse pairs. Using a matching function that generates an ordering of males and females that induces a pre-specified correlation, `rho` between the phenotypes that are being assorted on:

```{r}
generate_rho <- function(m, f, rho)
{
	stopifnot(length(m) == length(f))
	require(MASS)
	mvdat <- mvrnorm(n = length(m), mu=c(0,0), Sigma=matrix(c(1,rho,rho,1), 2,2))
	rm <- rank(mvdat[ , 1], ties.method = "first")
	rf <- rank(mvdat[ , 2], ties.method = "first")
	m_order <- order(m)
	f_order <- order(f)
	return(tibble(m = m_order[rm], f=f_order[rf]))
}
match_spouses <- function(dat, rho, matchm, matchf)
{
	matching <- generate_rho(dat[[matchm]], dat[[matchf]], rho)
	dat$gxm <- dat$gxm[matching$m]
	dat$gym <- dat$gym[matching$m]
	dat$xm <- dat$xm[matching$m]
	dat$ym <- dat$ym[matching$m]
	dat$um <- dat$um[matching$m]
	dat$gxf <- dat$gxf[matching$f]
	dat$gyf <- dat$gyf[matching$f]
	dat$xf <- dat$xf[matching$f]
	dat$yf <- dat$yf[matching$f]
	dat$uf <- dat$uf[matching$f]
	return(dat)
}
```

Create children

```{r}
generate_haplotypes <- function(g)
{
	h <- matrix(0,length(g),2)
	h[g == 2,] <- 1
	r <- sample(c(TRUE,FALSE), sum(g == 1), replace=TRUE)
	h[g == 1,][r,1] <- 1
	h[g == 1,][!r,2] <- 1
	stopifnot(all(rowSums(h) == g))
	return(h)
}
create_child_geno <- function(gm, gf)
{
	stopifnot(length(gm) == length(gf))
	tr <- sample(c(TRUE,FALSE), length(gm), replace=TRUE)
	ho <- matrix(0,length(gm), 2)
	hm <- generate_haplotypes(gm)
	hf <- generate_haplotypes(gf)
	ho[tr,1] <- hm[tr,1]
	ho[!tr,1] <- hm[!tr,2]
	ho[tr,2] <- hf[tr,1]
	ho[!tr,2] <- hf[!tr,2]
	return(rowSums(ho))
}
create_child <- function(dat, bgx, bgy, bxy, bux, buy)
{
	dat$gxo <- create_child_geno(dat$gxm, dat$gxf)
	dat$gyo <- create_child_geno(dat$gym, dat$gyf)
	dat$uo <- rnorm(nrow(dat))
	dat$xo <- make_phen(c(bgx, bux), cbind(dat$gxo, dat$uo))
	dat$yo <- make_phen(c(bxy, bgy, buy), cbind(dat$xo, dat$gyo, dat$uo))
	return(dat)
}
```

Run the simulation:

```{r}
bgx <- 0.2
bgy <- 0.8
bxy <- 0.0
bux <- 0
buy <- 0
rho <- 0.8
maf <- 0.2
dat <- generate_individuals(n=1000000, maf=maf, bgx=bgx, bgy=bgy, bxy=bxy, bux=bux, buy=buy)
dat <- match_spouses(dat, rho, "xm", "yf")
dat <- create_child(dat, bgx=bgx, bgy=bgy, bxy=bxy, bux=bux, buy=buy)
# Within male
cor(dat$ym, dat$xm)
cor(dat$xm, dat$gxm)
cor(dat$xm, dat$gym)
cor(dat$ym, dat$gxm)
cor(dat$ym, dat$gym)
```


```{r}
# Within female
cor(dat$yf, dat$xf)
cor(dat$xf, dat$gxf)
cor(dat$xf, dat$gyf)
cor(dat$yf, dat$gxf)
cor(dat$yf, dat$gyf)
```


```{r}
# Cross spousal phen
cor(dat$xm, dat$yf)
cor(dat$xm, dat$xf)
cor(dat$ym, dat$xf)
cor(dat$ym, dat$yf)
```

```{r}
# Cross spousal geno
cor(dat$gxm, dat$gxf)
cor(dat$gxm, dat$gyf)
cor(dat$gym, dat$gxf)
cor(dat$gym, dat$gyf)
```

```{r}
# Child
cor(dat$gxo, dat$gyo)
cor(dat$xo, dat$gyo)
cor(dat$gxo, dat$yo)
summary(lm(dat$xo ~ dat$gyo))
```

Expected covariance between gxm and gyf

$$
cov(g_{xm}, g_{yf}) = \rho \times cov(g_{xm}, x_m) cov(g_{yf}, y_f)
$$

Check:

```{r}
rho * cov(dat$gxm, dat$xm) * cov(dat$gyf, dat$yf)
cov(dat$gxm, dat$gyf)
```

Expected covariance between gxo and gyf


$$
\begin{aligned}
cov(g_{xo}, g_{yf}) &= cov(g_{xm}, g_{yf}) \cdot cor(g_{xm}, g_{xo}) \\
              &= \frac{1}{2} \cdot \rho \cdot cov(g_{xm}, x_m) \cdot cov(g_{yf}, y_f) \cdot cov(g_{xm}, g_{xo})
\end{aligned}
$$

Check:

```{r}
cor(dat$gxo, dat$gyf)
cor(dat$gxm, dat$gyf) * cor(dat$gxm, dat$gxo)
cov(dat$gxo, dat$gyf)
cov(dat$gxm, dat$gyf) * cor(dat$gxm, dat$gxo)
cov(dat$gxm, dat$gyf) * 0.5
rho * cov(dat$gxm, dat$xm) * cov(dat$gyf, dat$yf) * 0.5
```

Expected covariance between gxo and gyo

$$
\begin{aligned}
cov(gxo, gyo) &= 2 \cdot cov(gxm, gyf) \cdot cov(gxm, gxo) \cdot cov(gyf, gyo) \\
              &= 4 \cdot \rho \cdot cov(gxm, xm) \cdot cov(gyf, yf) \cdot cov(gxm, gxo) \cdot cov(gyf, gyo) \\
              &= \frac{1}{4} \cdot \rho \cdot cov(gxm, xm) \cdot cov(gyf, yf)
\end{aligned}
$$

Check:

```{r}
cov(dat$gxo, dat$gyo)
cov(dat$gxm, dat$gyf) * cor(dat$gxm, dat$gxo) * cor(dat$gyf, dat$gyo)
cov(dat$gxm, dat$gyf) / 4
with(dat, rho * cov(gxm, xm) * cov(gyf, yf)) / 4
rho * cov(dat$gxm, dat$xm) * cov(dat$gyf, dat$yf) / 4
```


Expected covariance between gyo and xo

$$
\begin{aligned}
cov(xo, gyo) &= cov(\gamma g_{xo}, gyo) \\
             &= \frac{1}{2} \cdot \gamma \cdot \rho \cdot cov(gxm, xm) \cdot cov(gyf, yf)
\end{aligned}
$$

```{r}
cov(dat$xo, dat$gyo)
bgx * rho * cov(dat$gxm, dat$xm) * cov(dat$gyf, dat$yf) / 2
```

```{r}
sim <- function(bgx, bgy, bxy, bux, buy, rho, maf, nid)
{
  dat <- generate_individuals(n=nid, maf=maf, bgx=bgx, bgy=bgy, bxy=bxy, bux=bux, buy=buy)
  dat <- match_spouses(dat, rho, "xm", "yf")
  dat <- create_child(dat, bgx=bgx, bgy=bgy, bxy=bxy, bux=bux, buy=buy)
  c(
    as.list(match.call()[-1]),
    emp = cov(dat$xo, dat$gyo),  
    exp = bgx * rho * cov(dat$gxm, dat$xm) * cov(dat$gyf, dat$yf) / 2,
    rsq = cor(dat$xo, dat$gyo)^2
  ) %>% as_tibble() %>% return()
}

params <- expand.grid(
  bgx = c(0.2, -0.2, 0.4, -0.4),
  bgy = c(0.1, -0.2),
  bxy = c(0.0, 0.2, -0.2),
  bux = 0,
  buy = 0,
  rho = c(0.4, 0.6, 0.8),
  maf = c(0.2, 0.7, 0.9),
  n = 300000
)
dim(params)
out <- lapply(1:nrow(params), function(i) {do.call(sim, params[i,])}) %>% bind_rows()
plot(out$emp, out$exp)
abline(lm(exp ~ emp, out))
summary(lm(exp ~ emp, out))
```

```{r}
head(out)
out$exp_rsq <- (0.5 * out$bgx^2 * out$rho * out$bgy * 2 * out$maf * (1-out$maf))^2
plot(sqrt(rsq) ~ sqrt(exp_rsq), out)
summary(lm(sqrt(rsq) ~ sqrt(exp_rsq), out))
```

Now convert to context of betas rather than covariances?

$$
\begin{aligned}
R_{x,gy} &= \frac{cov(x,gy)}{sd(x)sd(gy)} \\
& = \frac{1}{2} \frac{\gamma \cdot \rho \cdot \beta_{gx} var(gx) \cdot \beta_{gy} var(gy)}{sd(x) sd(gy)} \\
& = \frac{1}{2} \frac{\gamma \cdot \rho \cdot \beta_{gx} var(gx) \cdot \beta_{gy} var(gy)}{sd(x) sd(gy)} \\
\end{aligned}
$$

Now that we can generate a relationship between gy and x based on rho, and the variance explained in gy and gx, we can start to ask:

- What are the appropriate distributions of rho, bgx, bgy?
- What are all the "associating" variants for x?
- As sample size increases, what fraction of variants are due to assortative mating?
- If families are included, how much loss in detected variants is there?

- AM helps detect bgx
- AM leads to false positives of bgy

Simulate b_gx (e.g. education)
Simulate b_gy (e.g. height)
All causal effects for b_gx

```{r}
sim2 <- function(nsnp_1, h2_1, S_1, nsnp_2, h2_2, S_2, rho)
{
  map_1 <- tibble(snp=1:nsnp_1, af=runif(nsnp_1, 0.01, 0.99))
  map_2 <- tibble(snp=1:nsnp_2, af=runif(nsnp_2, 0.01, 0.99))
  params_1 <- generate_gwas_params(map=map_1, h2=h2_1, S=S_1, Pi=1)
  params_2 <- generate_gwas_params(map=map_2, h2=h2_2, S=S_2, Pi=1)
  vargx <- h2_1
  gamma <- 1
  params_2$rsq_x <- (0.5 * rho * sqrt(h2_1) * params_2$beta * sqrt(2 * params_2$af * (1-params_2$af)))^2
  params_1$rsq_x <- params_1$beta^2 * 2 * params_1$af * (1-params_1$af)
  params_x <- bind_rows(
    mutate(params_1, what="direct"),
    mutate(params_2, what="bias")
  )
  return(params_x)
}
params_x <- sim2(5000, 0.4, 0.2, 5000, 0.8, -1, 0.6)
d <- params_x %>%
  arrange(rsq_x) %>%
  mutate(ord=1:n(), perc = ntile(rsq_x, 100)) %>%
  group_by(perc) %>%
  summarise(rsq_x=mean(rsq_x), n=n(), prop=sum(what=="direct")/n())

sum(subset(params_x, what=="bias")$rsq_x)

d %>%
  ggplot(., aes(x=perc, y=rsq_x)) +
  geom_jitter(aes(colour=prop)) +
  scale_colour_gradient(low="red", high="blue") +
  labs(y="Variance explained by SNP in X", x="Percentile", colour="Probability of GWAS hit being a direct effect") +
  theme(legend.position="bottom")
```

Convert to power

```{r}
library(pwr)

params <- expand.grid(
  nsnp_1 = 20000,
  h2_1 = 0.7, 
  S_1 = 0, 
  nsnp_2 = 20000,
  h2_2 = 0.65, 
  S_2 = 0, 
  rho = c(0.18),
  n = c(seq(100000,900000,by=100000), seq(1000000,100000000,by=1000000))
)

d_power <- lapply(1:nrow(params), function(i)
{
  params_x <- do.call(sim2, params[i,] %>% dplyr::select(-n)) %>%
    mutate(power=pwr.r.test(n=params$n[i], r=sqrt(rsq_x), sig.level=5e-8)$power) %>%
    group_by(what) %>% summarise(nsig=sum(power), rsq=sum(power*rsq_x)) %>% 
    bind_cols(., params[i,])
}) %>% bind_rows()

ggplot(d_power, aes(y=nsig, x=n)) +
  geom_point(aes(colour=what)) +
  geom_line(aes(colour=what)) +
  geom_vline(data=tibble(cohort=c("UK Biobank", "Our Future Health"), n=c(500000, 5000000)), aes(xintercept=n, linetype=cohort)) +
  facet_grid(rho ~ .)




```

With a less polygenic trait

```{r}
d_power <- lapply(seq(100000,10000000,by=100000), function(n)
  {
    tibble(power = pwr.r.test(n=n, r=sqrt(params_x$rsq_x), sig.level=5e-8)$power, what=params_x$what, n=n)
}) %>% bind_rows()
d_power %>% group_by(n, what) %>% summarise(nsig=sum(power)) %>%
  ggplot(., aes(y=nsig, x=n)) +
  geom_point(aes(colour=what)) +
  geom_line(aes(colour=what)) +
  geom_vline(data=tibble(cohort=c("UK Biobank", "Our Future Health"), n=c(500000, 5000000)), aes(xintercept=n, linetype=cohort))
```

As power increases there are diminishing returns for direct GWAS hits and indirect hits are discovered faster. 

```{r}
d_power <- lapply(1:nrow(params), function(i)
{
  params_x <- do.call(sim2, params[i,] %>% dplyr::select(-n)) %>%
    mutate(power=pwr.r.test(n=params$n[i], r=sqrt(rsq_x), sig.level=5e-8)$power) %>%
    group_by(what) %>% summarise(nsig=sum(power), rsq=sum(rsq_x*power)) %>% 
    bind_cols(., params[i,])
}) %>% bind_rows()

params_x <- do.call(sim2, params[i,] %>% dplyr::select(-n)) %>%
    mutate(power=pwr.r.test(n=params$n[i], r=sqrt(rsq_x), sig.level=5e-8)$power)

sum(params_x$rsq_x)
table(params_x$what)
params_x %>% group_by(what) %>% summarise(sum(rsq_x))

d_power %>%
  ggplot(., aes(y=rsq, x=nsig)) +
  geom_point(aes(colour=what)) +
  geom_line(aes(colour=what))
```

For a given rsq what is the variance and beta of the pgs?

```{r}
map_1 <- tibble(snp=1:100, af=runif(100, 0.01, 0.99))
params_1 <- generate_gwas_params(map=map_1, h2=0.4, S=0, Pi=1)
sum(params_1$beta^2 * 2 * params_1$af * (1-params_1$af))

make_geno <- function(nid, nsnp, af)
{
  stopifnot(length(af) == nsnp | length(af) == 1)
  if(length(af) == 1)
  {
    simulateGP::make_geno(nid=nid, nsnp=nsnp, af=af) %>%
      return()
  } else {
    lapply(af, function(p)
      {
      rbinom(nid, 2, p)
    }) %>% 
      bind_cols() %>% 
      as.matrix() %>%
      return()
  }
}

g <- make_geno(100000, 100, map_1$af)
dim(g)
class(g)
colMeans(g)/2
e <- rnorm(100000, 0, sqrt(0.6))
prs <- g %*% params_1$beta
x <- prs + e
var(x)
var(prs)
var(e)
```



## Number of sib pairs

20k sib pairs from 500k individuals aged 40-69. 

Assume 2.4 children per family, and all 500k are from a single generation

```{r}
nfam <- 500000 / 2.4

# How many 40-69 in UK
npop <- 3500000 * 6

# How many families
nfam <- npop / 2.4

nchildren <- rpois(nfam,2.4)
table(nchildren)
id <- tibble(
  famid = rep(1:nfam, nchildren),
  iid = 1:length(famid)
)
nsib <- tibble(
  famid = 1:nfam,
  nsibpair = nchildren * (nchildren-1)/2
)
table(nsib$nsibpair)

sum(nsib$nsibpair)

id_sample <- id[sample(1:nrow(id), 500000, replace=FALSE), ]
idfam <- id_sample %>% group_by(famid) %>% summarise(n=n())
idfam$nsibpair <- idfam$n * (idfam$n-1) / 2
sum(idfam$nsibpair)
```
















